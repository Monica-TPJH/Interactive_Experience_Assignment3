# Alternative: Using Ollama instead of LMStudio
import ollama
import sys

print("ğŸ¦™ Testing connection to Ollama server...")
print("ğŸ“¡ Default Ollama URL: http://localhost:11434")
print("---")

try:
    # Test if Ollama is running and has models
    models = ollama.list()
    
    if not models['models']:
        print("âš ï¸  No models found in Ollama!")
        print("ğŸ“¥ Please install a model first:")
        print("   ollama pull llama3")
        print("   or")
        print("   ollama pull llama3.2")
        sys.exit(1)
    
    print("âœ… Ollama is running!")
    print("ğŸ“š Available models:")
    for model in models['models']:
        print(f"   - {model['name']}")
    
    # Use the first available model
    model_name = models['models'][0]['name']
    print(f"\nğŸ¤– Using model: {model_name}")
    print("---")
    
    # Generate completion
    response = ollama.chat(
        model=model_name,
        messages=[
            {"role": "system", "content": "Always answer in rhymes."},
            {"role": "user", "content": "Introduce yourself."}
        ]
    )
    
    print("âœ… SUCCESS! Ollama connection working!")
    print("ğŸ¤– AI Response:")
    print("---")
    print(response['message']['content'])
    print("---")
    print("ğŸ“Š Model used:", response['model'])
    print("â±ï¸  Response time:", f"{response.get('total_duration', 0) / 1000000000:.2f} seconds")
    
except ollama.ResponseError as e:
    print(f"âŒ Ollama API Error: {e}")
    print("\nğŸ“‹ TROUBLESHOOTING:")
    print("1. Make sure Ollama is installed: https://ollama.ai")
    print("2. Start Ollama: ollama serve")
    print("3. Pull a model: ollama pull llama3")
    
except ConnectionError:
    print("âŒ ERROR: Cannot connect to Ollama server!")
    print("\nğŸ“‹ TROUBLESHOOTING STEPS:")
    print("1. ğŸ“¥ Install Ollama from https://ollama.ai")
    print("2. ğŸš€ Start Ollama server: ollama serve")
    print("3. ğŸ“¦ Download a model: ollama pull llama3")
    print("4. ğŸ” Run this script again")
    
except Exception as e:
    print(f"âŒ Unexpected error: {str(e)}")
    print("\nğŸ“‹ TROUBLESHOOTING:")
    print("1. Make sure Ollama is installed and running")
    print("2. Try: ollama serve")
    print("3. Try: ollama pull llama3")
    print("4. Check if port 11434 is available")