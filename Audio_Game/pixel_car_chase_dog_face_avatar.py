#!/usr/bin/env python3
"""
Face Avatar Pixel Car Chase Dog Game

åŠŸèƒ½:
- å¯åŠ¨å‰å…ˆç”¨æ‘„åƒå¤´å½•å…¥äººè„¸, æˆåŠŸåå°†äººè„¸è½¬æ¢ä¸ºåƒç´ é£å¤´åƒ
- è¯†åˆ«å¥½çš„äººè„¸å¤´åƒæ˜¾ç¤ºåœ¨æ¸¸æˆå³ä¾§åŒºåŸŸ
- å¿…é¡»å½•å…¥æˆåŠŸåæ‰å¼€å§‹æ¸¸æˆ

ä¾èµ–: opencv-python, numpy, matplotlib, pyaudio (æ¸¸æˆå·²ä½¿ç”¨)

ç”¨æ³•:
- ç›´æ¥è¿è¡Œæœ¬æ–‡ä»¶ã€‚æ‘„åƒå¤´çª—å£ä¸­æŒ‰ C é”®æ‹æ‘„, æŒ‰ Q é”®é€€å‡º
"""

import time
from typing import Optional, Tuple

import numpy as np

try:
    import cv2
except Exception:
    print("éœ€è¦å®‰è£… OpenCV: pip install opencv-python")
    raise

try:
    from pixel_car_chase_dog import PixelCarChaseDogGame
except Exception:
    # å…¼å®¹ä»é¡¹ç›®æ ¹ç›®å½•è¿è¡Œ
    from Audio_Game.pixel_car_chase_dog import PixelCarChaseDogGame


def _largest_face(faces: np.ndarray) -> Optional[Tuple[int, int, int, int]]:
    if faces is None or len(faces) == 0:
        return None
    areas = [(w * h, (x, y, w, h)) for (x, y, w, h) in faces]
    areas.sort(key=lambda t: t[0], reverse=True)
    return areas[0][1]


def _pixelate_rgb(img_rgb: np.ndarray, grid: int = 16, out_size: int = 128) -> np.ndarray:
    """å°†RGBå›¾åƒåƒç´ åŒ–+é¢œè‰²é‡åŒ–ä¸ºåƒç´ é£å¤´åƒ"""
    if img_rgb is None or img_rgb.size == 0:
        raise ValueError("ç©ºå›¾åƒï¼Œæ— æ³•åƒç´ åŒ–")
    h, w = img_rgb.shape[:2]
    # ä¿è¯æ­£æ–¹å½¢: ä»¥ä¸­å¿ƒè£å‰ªåˆ°æ­£æ–¹å½¢
    side = min(h, w)
    y0 = (h - side) // 2
    x0 = (w - side) // 2
    patch = img_rgb[y0:y0 + side, x0:x0 + side]

    # ç¼©å°åˆ°gridÃ—gridå†æ”¾å¤§
    small = cv2.resize(patch, (grid, grid), interpolation=cv2.INTER_AREA)

    # ç®€å•è°ƒè‰²æ¿é‡åŒ–ï¼ˆæ¯é€šé“4çº§: 0, 85, 170, 255ï¼‰
    step = 85
    quant = ((small // step) * step).astype(np.uint8)

    # æ”¾å¤§è¾“å‡º
    out = cv2.resize(quant, (out_size, out_size), interpolation=cv2.INTER_NEAREST)

    # è½»å¾®å¯¹æ¯”å¢å¼ºï¼Œå¢åŠ â€œåƒç´ å‘³é“â€
    out = cv2.convertScaleAbs(out, alpha=1.15, beta=0)
    return out


def _open_any_camera(preferred_indices=(0, 1, 2)) -> Optional[cv2.VideoCapture]:
    """åœ¨ macOS ä¸Šå°è¯•å¤šç§åç«¯ä¸ç´¢å¼•æ‰“å¼€æ‘„åƒå¤´ã€‚æˆåŠŸåˆ™è¿”å›å·²æ‰“å¼€çš„ VideoCaptureã€‚"""
    backends = []
    cap_avf = getattr(cv2, 'CAP_AVFOUNDATION', None)
    if cap_avf is not None:
        backends.append(cap_avf)
    backends.append(None)  # é»˜è®¤åç«¯

    for backend in backends:
        for idx in preferred_indices:
            cap = cv2.VideoCapture(idx, backend) if backend is not None else cv2.VideoCapture(idx)
            if cap.isOpened():
                return cap
            cap.release()
    return None


def capture_face_avatar(window_name: str = "Face Capture", timeout_s: int = 60) -> np.ndarray:
    """æ‰“å¼€æ‘„åƒå¤´æ•è·äººè„¸ï¼Œè¿”å›åƒç´ åŒ–çš„RGBå¤´åƒå›¾åƒ (H, W, 3)"""
    cap = _open_any_camera()
    if not cap or not cap.isOpened():
        raise RuntimeError(
            "æ— æ³•æ‰“å¼€æ‘„åƒå¤´ã€‚è¯·æ£€æŸ¥: 1) ç³»ç»Ÿåå¥½è®¾ç½®>å®‰å…¨æ€§ä¸éšç§>éšç§>ç›¸æœº æ˜¯å¦å…è®¸ VS Code/Terminal/python; 2) å…¶å®ƒåº”ç”¨æ˜¯å¦å ç”¨æ‘„åƒå¤´; 3) å¤–æ¥æ‘„åƒå¤´å·²è¿æ¥ã€‚"
        )

    cascade_path = cv2.data.haarcascades + "haarcascade_frontalface_default.xml"
    face_cascade = cv2.CascadeClassifier(cascade_path)
    if face_cascade.empty():
        cap.release()
        raise RuntimeError("æ— æ³•åŠ è½½äººè„¸åˆ†ç±»å™¨: " + cascade_path)

    print("æ‰“å¼€æ‘„åƒå¤´... æŒ‰ C æ‹æ‘„å¤´åƒ, æŒ‰ Q é€€å‡º")
    start = time.time()
    avatar: Optional[np.ndarray] = None

    while True:
        ok, frame = cap.read()
        if not ok:
            continue
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(80, 80))
        for (x, y, w, h) in faces:
            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)

        cv2.putText(frame, "Press 'C' to capture, 'Q' to quit", (20, 30),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2, cv2.LINE_AA)
        cv2.imshow(window_name, frame)

        key = cv2.waitKey(1) & 0xFF
        if key in (ord('q'), ord('Q')):
            cap.release()
            cv2.destroyAllWindows()
            raise KeyboardInterrupt("ç”¨æˆ·å–æ¶ˆ")
        if key in (ord('c'), ord('C')) and len(faces) > 0:
            # ä½¿ç”¨æœ€å¤§çš„äººè„¸
            (x, y, w, h) = _largest_face(faces)
            pad = int(0.1 * max(w, h))
            x0 = max(0, x - pad)
            y0 = max(0, y - pad)
            x1 = min(frame.shape[1], x + w + pad)
            y1 = min(frame.shape[0], y + h + pad)
            face_bgr = frame[y0:y1, x0:x1]
            face_rgb = cv2.cvtColor(face_bgr, cv2.COLOR_BGR2RGB)
            avatar = _pixelate_rgb(face_rgb, grid=18, out_size=100)
            break

        if timeout_s and (time.time() - start) > timeout_s:
            print("è¶…æ—¶æœªæ‹æ‘„ï¼Œè‡ªåŠ¨é€€å‡º")
            cap.release()
            cv2.destroyAllWindows()
            raise TimeoutError("äººè„¸å½•å…¥è¶…æ—¶")

    cap.release()
    cv2.destroyAllWindows()
    if avatar is None:
        raise RuntimeError("æœªè·å–åˆ°å¤´åƒ")
    return avatar


def choose_image_as_avatar() -> np.ndarray:
    """å¼¹å‡ºæ–‡ä»¶é€‰æ‹©æˆ–å‘½ä»¤è¡Œè¾“å…¥ï¼Œé€‰æ‹©ä¸€å¼ å›¾ç‰‡ä½œä¸ºå¤´åƒ; æ£€æµ‹æœ€å¤§äººè„¸å¹¶åƒç´ åŒ–ã€‚"""
    # ä¼˜å…ˆä½¿ç”¨æ–‡ä»¶é€‰æ‹©å¯¹è¯æ¡†
    img_path: Optional[str] = None
    try:
        import tkinter as tk
        from tkinter import filedialog
        root = tk.Tk()
        root.withdraw()
        img_path = filedialog.askOpenFileDialog(title='é€‰æ‹©å¤´åƒå›¾ç‰‡')  # type: ignore[attr-defined]
    except Exception:
        # æŸäº›ç¯å¢ƒæ²¡æœ‰Tkï¼Œé€€å›å‘½ä»¤è¡Œ
        pass

    if not img_path:
        try:
            img_path = input("æœªèƒ½æ‰“å¼€æ‘„åƒå¤´ã€‚è¯·è¾“å…¥ä¸€å¼ å›¾ç‰‡è·¯å¾„ä½œä¸ºå¤´åƒ(å›è½¦è·³è¿‡é€€å‡º): ").strip()
        except Exception:
            img_path = None

    if not img_path:
        raise RuntimeError("æœªé€‰æ‹©å›¾ç‰‡")

    bgr = cv2.imread(img_path)
    if bgr is None:
        raise RuntimeError("æ— æ³•è¯»å–æ‰€é€‰å›¾ç‰‡: " + img_path)
    rgb = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)

    # å°è¯•æ£€æµ‹äººè„¸ä»¥è£å‰ªï¼›è‹¥å¤±è´¥åˆ™å±…ä¸­è£å‰ª
    try:
        cascade_path = cv2.data.haarcascades + "haarcascade_frontalface_default.xml"
        face_cascade = cv2.CascadeClassifier(cascade_path)
        if not face_cascade.empty():
            gray = cv2.cvtColor(bgr, cv2.COLOR_BGR2GRAY)
            faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(80, 80))
            if len(faces) > 0:
                (x, y, w, h) = _largest_face(faces)
                pad = int(0.2 * max(w, h))
                x0 = max(0, x - pad)
                y0 = max(0, y - pad)
                x1 = min(bgr.shape[1], x + w + pad)
                y1 = min(bgr.shape[0], y + h + pad)
                rgb = cv2.cvtColor(bgr[y0:y1, x0:x1], cv2.COLOR_BGR2RGB)
    except Exception:
        pass

    return _pixelate_rgb(rgb, grid=18, out_size=160)


class FaceAvatarCarChaseGame(PixelCarChaseDogGame):
    def __init__(self, avatar_img_rgb: np.ndarray):
        self.avatar_img_rgb = avatar_img_rgb
        super().__init__()

    def setup_graphics(self):
        # å…ˆæ„å»ºåŸºç¡€åƒç´ ä¸–ç•Œ
        super().setup_graphics()

        # åœ¨å³ä¾§æ”¾ç½®ç©å®¶å¤´åƒï¼ˆåƒç´ é£ï¼‰
        try:
            img = self.avatar_img_rgb
            if img is not None:
                # å¤´åƒæ˜¾ç¤ºåŒºåŸŸï¼ˆä»¥æ¸¸æˆä¸–ç•Œåæ ‡è®¡ï¼‰
                # ç¼©å°åˆ°ä¸è¶…è¿‡å·¦ä¾§ä¿¡æ¯æ¡†å¤§å°ï¼ˆä¿¡æ¯æ¡†çº¦é«˜1.2ã€å®½1.92ä¸–ç•Œå•ä½ï¼‰
                w_units = 1.2
                h_units = 1.2
                x0 = self.GAME_WIDTH - w_units - 0.4  # å³ä¾§ç•™è¾¹è·
                # æ”¾åœ¨å³ä¸Šè§’ï¼ˆé¡¶éƒ¨åŒæ ·ç•™è¾¹è·ï¼‰
                y0 = self.GAME_HEIGHT - h_units - 0.4
                self.avatar_artist = self.ax.imshow(img, extent=(x0, x0 + w_units, y0, y0 + h_units), zorder=8)

                # ç®€å•çš„åƒç´ è¾¹æ¡†
                border_color = '#FFFFFF'
                border_size = 0.06
                for dx in np.arange(0, w_units + border_size, border_size):
                    self.create_pixel_block(x0 + dx, y0, border_size, border_color)
                    self.create_pixel_block(x0 + dx, y0 + h_units - border_size, border_size, border_color)
                for dy in np.arange(0, h_units + border_size, border_size):
                    self.create_pixel_block(x0, y0 + dy, border_size, border_color)
                    self.create_pixel_block(x0 + w_units - border_size, y0 + dy, border_size, border_color)
        except Exception as e:
            print(f"ç»˜åˆ¶å¤´åƒå¤±è´¥: {e}")


def main():
    print("=" * 60)
    print("ğŸ§‘â€ğŸ¤ äººè„¸å¤´åƒå½•å…¥ (åƒç´ é£)")
    print("- è¯·é¢å¯¹æ‘„åƒå¤´ï¼ŒæŒ‰ C æ‹æ‘„å¤´åƒï¼ŒæŒ‰ Q é€€å‡º")
    print("=" * 60)
    try:
        avatar = capture_face_avatar()
    except KeyboardInterrupt:
        print("ç”¨æˆ·å–æ¶ˆï¼Œé€€å‡º")
        return
    except Exception as e:
        print(f"å¤´åƒå½•å…¥å¤±è´¥: {e}")
        # æ‘„åƒå¤´ä¸å¯ç”¨æ—¶ï¼Œå°è¯•ä»å›¾ç‰‡é€‰æ‹©
        try:
            print("æ”¹ä¸ºé€‰æ‹©æœ¬åœ°å›¾ç‰‡ä½œä¸ºå¤´åƒ...")
            avatar = choose_image_as_avatar()
        except Exception as e2:
            print(f"å›¾ç‰‡é€‰å–ä¹Ÿå¤±è´¥: {e2}")
            return

    print("å¤´åƒå·²å½•å…¥ï¼Œå¯åŠ¨æ¸¸æˆ...")
    try:
        game = FaceAvatarCarChaseGame(avatar)
        game.start_game()
    except KeyboardInterrupt:
        print("\nPIXEL GAME INTERRUPTED")
    except Exception as e:
        print(f"PIXEL GAME ERROR: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
